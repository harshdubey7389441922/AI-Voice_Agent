# ğŸ™ï¸ AI Voice Agent

An AI-powered conversational assistant that listens, understands, and responds in real time â€” using **Murf AI**, **Google Gemini**, and **AssemblyAI**.

This project was built as part of the **#30DaysofVoiceAgents** challenge by Murf AI.

---

## ğŸš€ Features
- ğŸ¤ **Voice Input** â€“ Record speech directly from the browser.
- ğŸ“ **Speech-to-Text** â€“ Uses **AssemblyAI** for transcription.
- ğŸ¤– **AI Responses** â€“ Powered by **Google Gemini API**.
- ğŸ’¬ **Chat Memory** â€“ Keeps conversation history for context.
- ğŸ”Š **Text-to-Speech** â€“ Uses **Murf AI** to generate realistic voice.
- ğŸ§¹ **Clear Chat** â€“ Reset conversation anytime.
- âš ï¸ **Error Handling** â€“ Fallback voice/text if APIs fail.
- ğŸ¨ **Revamped UI** â€“ Single toggle button, clean layout.

---

## ğŸ› ï¸ Tech Stack
- **Backend:** FastAPI (Python)
- **Frontend:** HTML, CSS, JavaScript
- **APIs:**
  - [AssemblyAI](https://www.assemblyai.com/) â€“ Speech-to-Text
  - [Google Gemini](https://ai.google/) â€“ AI responses
  - [Murf AI](https://murf.ai/) â€“ Text-to-Speech

---

## ğŸ—ï¸ Architecture
```mermaid
graph TD;
    A[ğŸ¤ User Voice] -->|Audio| B[AssemblyAI STT]
    B --> C[ğŸ“ Transcript]
    C --> D[ğŸ’¬ Add to Chat Memory]
    D --> E[Google Gemini LLM]
    E --> F[ğŸ“ AI Response]
    F --> G[Murf AI TTS]
    G --> H[ğŸ§ Audio Playback]
```
---
## Project Structure
```mermaid
.
â”œâ”€â”€ main.py               # FastAPI backend
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css         # UI styles
â”‚   â”œâ”€â”€ script.js         # Frontend logic
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Web UI
â”œâ”€â”€ .env                  # API keys & config
â””â”€â”€ README.md             # Project documentation
```
---
âš™ï¸ Setup Instructions

1ï¸âƒ£ Install Python Packages
```
pip install fastapi uvicorn python-dotenv requests
```

2ï¸âƒ£ Add Environment Variables

Create a .env file in the root folder:

```
MURF_API_KEY=your_murf_api_key
MURF_VOICE_ID=your_murf_voice_id
GEMINI_API_KEY=your_gemini_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
```

3ï¸âƒ£ Run the Server
```
uvicorn main:app --reload
```
---

âš™ï¸ How It Works
```
1. User clicks record
   Browser starts capturing microphone input.

2. Send audio to backend
   Audio is sent to FastAPI backend via /agent/chat/{session_id} endpoint.

3. Speech-to-Text
   Backend sends audio to AssemblyAI for transcription.

4. Contextual AI response
   Transcript + chat history sent to Google Gemini for generating a response.

5. Text-to-Speech
   Response text sent to Murf AI for natural voice output.

6. Play audio
   The browser automatically plays the generated audio.

7. Maintain chat memory
   Session-based memory stores past messages for context.

8. Error Handling
   If any API fails, a fallback voice/text response is sent.
```
---
ğŸ“¦ Dependencies

Install using pip:
```
pip install fastapi uvicorn python-dotenv requests
```

Libraries used:
```
fastapi â€“ API server

uvicorn â€“ ASGI server to run FastAPI

python-dotenv â€“ Load .env variables

requests â€“ For calling external APIs

uuid â€“ Generate session IDs (built-in)

os â€“ Access environment variables (built-in)
```
